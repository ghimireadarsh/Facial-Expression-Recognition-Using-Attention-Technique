{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSL8LElj_VUC"
   },
   "source": [
    "VGG16 trained on VGGFace is used as feature extraction or transfer learning model, then flatten layer is added before classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYdUsK7g_NB6"
   },
   "outputs": [],
   "source": [
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbw3j1jwAIeg"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9HZ2zZP2ABG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.engine import  Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
    "from keras import optimizers\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight # For balancing the class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R3yJCe9SBF8z"
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83225eIsAXf_"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BM4OUrNJGaE3"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTswhELQBwSn"
   },
   "outputs": [],
   "source": [
    "# data are in dataset folder in zipped format\n",
    "!ls \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlcZtbPnB-_M"
   },
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C3Fwdx4BnHD"
   },
   "outputs": [],
   "source": [
    "# This creates a temporary folder in drive root folder, so it will have to be reloaded again when required after terminating the session\n",
    "# Permanent data are stored in dataset in zipped format\n",
    "# This copies the zipped file and store in root of google drive temporarily \n",
    "# This allows colab to run faster by taking data from root folder, rather than from actual drive location.\n",
    "! rm -rf Training; mkdir Training\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/Training.zip\" -d Training\n",
    "\n",
    "! rm -rf Validation; mkdir Validation\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/PublicTest.zip\" -d Validation\n",
    "\n",
    "! rm -rf Test; mkdir Test\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/PrivateTest.zip\" -d Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0rEd4qTFZOW"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVqOHBZ2Ek2p"
   },
   "outputs": [],
   "source": [
    "!ls -l Training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9J_Y3AuiEvLH"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Training/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuFgVnVqFIr-"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Validation/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yunR8QsDFfS7"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Test/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUjWv1Ty2ABV"
   },
   "outputs": [],
   "source": [
    "train_dir = \"Training/\"\n",
    "validation_dir = \"Validation/\"\n",
    "test_dir = \"Test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc4QatxPGVgf"
   },
   "source": [
    "## All data are ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Image generator with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndeyAEJp-Hz-"
   },
   "outputs": [],
   "source": [
    "# Image height and width initialization\n",
    "img_height = 224\n",
    "img_height = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator setup\n",
    "batch_size = 50\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   featurewise_center=False,\n",
    "                                   featurewise_std_normalization=False,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True\n",
    "                                   )\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight_computer():\n",
    "  \"\"\"\n",
    "    Training Data categories and number of samples in them\n",
    "    Angry: 3995\n",
    "    Disgust: 436\n",
    "    Fear: 4097\n",
    "    Happy: 7215\n",
    "    Neutral: 4965\n",
    "    Sad: 4830\n",
    "    Surprise: 3171\n",
    "  \"\"\"\n",
    "  samples_per_label = [3995, 436, 4097, 7215, 4965, 4830, 3171]\n",
    "  total_samples = sum(samples_per_label)\n",
    "  return dict([(i, total_samples/(7*j)) for (i,j) in enumerate(samples_per_label)]) # https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "class_weights = class_weight_computer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RABx6AF0GUcK"
   },
   "outputs": [],
   "source": [
    "# https://github.com/rcmalli/keras-vggface#projects--blog-posts\n",
    "conv_base = VGGFace(model='vgg16',\n",
    "                  include_top = False,\n",
    "                  input_shape = (img_height, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFZj8WNrGUNQ"
   },
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFh7MWkeHOB5"
   },
   "outputs": [],
   "source": [
    "DROP_OUT_RATE = 0.5\n",
    "FROZEN_LAYER_NUM = len(conv_base.layers)\n",
    "FROZEN_LAYER_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOo4x3nMHjVr"
   },
   "outputs": [],
   "source": [
    "print(\"Number of trainable weights before freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yolc7LGnHwpg"
   },
   "outputs": [],
   "source": [
    "# conv_base.trainable = False\n",
    "for i in range(FROZEN_LAYER_NUM):\n",
    "    conv_base.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "824MFNkNHx1Z"
   },
   "outputs": [],
   "source": [
    "print(\"Number of trainable weights after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAOD8j9lH7SR"
   },
   "outputs": [],
   "source": [
    "print(conv_base.get_layer('conv5_3').trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U1OJIxdIVHo"
   },
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Classifier on top of pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCBKZp9vG2zW"
   },
   "outputs": [],
   "source": [
    "last_layer = conv_base.get_layer('pool5').output\n",
    "\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dropout(DROP_OUT_RATE)(x)\n",
    "x = Dense(512, activation='relu', name='fc6')(x)\n",
    "x = Dropout(DROP_OUT_RATE)(x)\n",
    "x = Dense(512, activation='relu', name='fc7')(x)\n",
    "out = Dense(7, activation='softmax', name='classifier')(x)\n",
    "\n",
    "model = Model(conv_base.input, out)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001,), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAd4XKGCJ2ta"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyDmy4jw2AB3"
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "EPOCHS = 50\n",
    "training_samples = 28709\n",
    "validation_samples = 3589\n",
    "test_samples = 3589\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=training_samples//batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples//batch_size,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEpAZsie2AB9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy with freezed Conv base of VGG16 pretrained on VGGFACE2')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and Validation Loss with freeze conv base of VGG16 pretrained on VGGFACE2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 11632,
     "status": "ok",
     "timestamp": 1602529728908,
     "user": {
      "displayName": "Adarsh Ghimire",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiJ9rHrsqUAXXZP8Syzv-mcB6GhQzMybMiiiSFyKw=s64",
      "userId": "03649801403498526934"
     },
     "user_tz": -345
    },
    "id": "97OLeZqGMUvH",
    "outputId": "324508e6-c795-481c-95e5-b3a6f364f3a1"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, 3589//50 )\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmPrecLaMwpV"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'test_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR2kw25cN8gZ"
   },
   "outputs": [],
   "source": [
    "print(epoch_str)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfWTZzbvNiG5"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_VGGFACE/\" + 'VGG16_VGG_FACE_flatten' + epoch_str + val_acc + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fdFVHApQS2D"
   },
   "source": [
    "### Finetuning the above model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the last layer only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image generators and data preparation codes are pre-loaded before the below session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_VGGFACE/VGG16_VGG_FACE_flatten-EPOCHS_50val_acc_0.388.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvMHz69-Q_c_"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvMg3rm5RFi9"
   },
   "outputs": [],
   "source": [
    "# Choosing last convolutional blocks of VGG16 to trainable as well for fine tuning\n",
    "set_trainable = False\n",
    "for layer in model.layers:\n",
    "  if layer.name == \"conv5_3\":\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GQv6JzPSE2Y"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IzUxBoaRo_C"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGa5Qy9uRrZL"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "training_samples = 28709\n",
    "validation_samples = 3589\n",
    "test_samples = 3589\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=training_samples//batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples//batch_size,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IaKe506SGpD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy while fine tuning VGG16 trained on VGGFACE2')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.title('Training and Validation Loss while fine tuning VGG16 trained on VGGFACE2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaiP7mIEgnmv"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyLHQRapg0i8"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'val_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xLYGco6g5JO"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_VGGFACE/\" + 'VGG16_VGG_FACE_flatten_finetuned' + epoch_str + val_acc + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_VGGFACE/VGG16_VGG_FACE_flatten-EPOCHS_50val_acc_0.558.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvMHz69-Q_c_"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvMg3rm5RFi9"
   },
   "outputs": [],
   "source": [
    "# Choosing two last convolutional blocks of VGG16 to trainable as well for fine tuning\n",
    "set_trainable = False\n",
    "for layer in model.layers:\n",
    "  if layer.name == \"conv5_2\":\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GQv6JzPSE2Y"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IzUxBoaRo_C"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGa5Qy9uRrZL"
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "EPOCHS = 50\n",
    "training_samples = 28709\n",
    "validation_samples = 3589\n",
    "test_samples = 3589\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=training_samples//batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples//batch_size,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IaKe506SGpD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy while fine tuning VGG16 trained on VGGFACE2')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.title('Training and Validation Loss while fine tuning VGG16 trained on VGGFACE2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaiP7mIEgnmv"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyLHQRapg0i8"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'val_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xLYGco6g5JO"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_VGGFACE/\" + 'VGG16_VGG_FACE_flatten_finetuned' + epoch_str + val_acc + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the three layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_VGGFACE/VGG16_VGG_FACE_flatten-EPOCHS_50val_acc_0.583.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvMHz69-Q_c_"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvMg3rm5RFi9"
   },
   "outputs": [],
   "source": [
    "# Choosing last three convolutional blocks of VGG16 to trainable as well for fine tuning\n",
    "set_trainable = False\n",
    "for layer in model.layers:\n",
    "  if layer.name == \"conv5_1\":\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GQv6JzPSE2Y"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IzUxBoaRo_C"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.000001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGa5Qy9uRrZL"
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "EPOCHS = 50\n",
    "training_samples = 28709\n",
    "validation_samples = 3589\n",
    "test_samples = 3589\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=training_samples//batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples//batch_size,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IaKe506SGpD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy while fine tuning VGG16 trained on VGGFACE2')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
    "plt.title('Training and Validation Loss while fine tuning VGG16 trained on VGGFACE2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaiP7mIEgnmv"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyLHQRapg0i8"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'val_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xLYGco6g5JO"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_VGGFACE/\" + 'VGG16_VGG_FACE_flatten_finetuned' + epoch_str + val_acc + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nEvaluate on test data')\n",
    "results_test = model.evaluate_generator(test_generator, 3589//50)\n",
    "print('test loss, test acc:', results_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1 Transfer learning with VGG16(VGGFACE  flatten) on fer2013.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
