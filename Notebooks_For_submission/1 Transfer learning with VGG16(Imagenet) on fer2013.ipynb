{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9HZ2zZP2ABG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.engine import  Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R3yJCe9SBF8z"
   },
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83225eIsAXf_"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BM4OUrNJGaE3"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTswhELQBwSn"
   },
   "outputs": [],
   "source": [
    "# data are in dataset folder in zipped format\n",
    "!ls \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlcZtbPnB-_M"
   },
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C3Fwdx4BnHD"
   },
   "outputs": [],
   "source": [
    "# This creates a temporary folder in drive root folder, so it will have to be reloaded again when required after terminating the session\n",
    "# Permanent data are stored in dataset in zipped format\n",
    "# This copies the zipped file and store in root of google drive temporarily \n",
    "# This allows colab to run faster by taking data from root folder, rather than from actual drive location.\n",
    "! rm -rf Training; mkdir Training\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/Training.zip\" -d Training\n",
    "\n",
    "! rm -rf Validation; mkdir Validation\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/PublicTest.zip\" -d Validation\n",
    "\n",
    "! rm -rf Test; mkdir Test\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/PrivateTest.zip\" -d Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0rEd4qTFZOW"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVqOHBZ2Ek2p"
   },
   "outputs": [],
   "source": [
    "!ls -l Training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9J_Y3AuiEvLH"
   },
   "outputs": [],
   "source": [
    "# Counting the images in each training data categories\n",
    "%%bash\n",
    "root='Training/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuFgVnVqFIr-"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Validation/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yunR8QsDFfS7"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Test/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUjWv1Ty2ABV"
   },
   "outputs": [],
   "source": [
    "train_dir = \"Training/\"\n",
    "validation_dir = \"Validation/\"\n",
    "test_dir = \"Test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc4QatxPGVgf"
   },
   "source": [
    "## All data are ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Image generator with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2LZgfdwTata"
   },
   "outputs": [],
   "source": [
    "# Setting image height and width\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator setup\n",
    "batch_size = 50\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   featurewise_center=False,\n",
    "                                   featurewise_std_normalization=False,\n",
    "                                   rotation_range=90,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True\n",
    "                                   )\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight_computer():\n",
    "  \"\"\"\n",
    "    Training Data categories and number of samples in them\n",
    "    Angry: 3995\n",
    "    Disgust: 436\n",
    "    Fear: 4097\n",
    "    Happy: 7215\n",
    "    Neutral: 4965\n",
    "    Sad: 4830\n",
    "    Surprise: 3171\n",
    "  \"\"\"\n",
    "  samples_per_label = [3995, 436, 4097, 7215, 4965, 4830, 3171]\n",
    "  total_samples = sum(samples_per_label)\n",
    "  return dict([(i, total_samples/(7*j)) for (i,j) in enumerate(samples_per_label)]) # https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "class_weights = class_weight_computer()\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RABx6AF0GUcK"
   },
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights=\"imagenet\",\n",
    "                  include_top=False,\n",
    "                  input_shape=(img_height, img_width, 3)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFZj8WNrGUNQ"
   },
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOo4x3nMHjVr"
   },
   "outputs": [],
   "source": [
    "print(\"Number of trainable weights before freezing the conv base:\", len(conv_base.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print(\"Number of trainable weights after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U1OJIxdIVHo"
   },
   "outputs": [],
   "source": [
    "conv_base.summary() # Checking if the model has been frozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Classifier on top of pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCBKZp9vG2zW"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "DROP_OUT_RATE = 0.5\n",
    "EPOCHS = 50\n",
    "last_layer = conv_base.output\n",
    "\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dropout(DROP_OUT_RATE)(x)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dropout(DROP_OUT_RATE)(x)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "out = Dense(7, activation='softmax', name='classifier')(x)\n",
    "\n",
    "model = Model(conv_base.input, out)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
    "model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAd4XKGCJ2ta"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyDmy4jw2AB3"
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "EPOCHS = 50\n",
    "training_samples = 28709\n",
    "validation_samples = 3589\n",
    "test_samples = 3589\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=training_samples//batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples//batch_size,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEpAZsie2AB9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy with freezed Conv base of VGG16')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and Validation Loss with freeze Conv base of VGG16')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97OLeZqGMUvH"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmPrecLaMwpV"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'test_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR2kw25cN8gZ"
   },
   "outputs": [],
   "source": [
    "print(epoch_str)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfWTZzbvNiG5"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_path = \"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_Imagenet/VGG16\" + epoch_str + val_acc + '.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc-GhhISu4DY"
   },
   "source": [
    "### Fine Tuning VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3ZSxwX116bU"
   },
   "source": [
    "### Fine tuning the last Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image generators and data preparation codes are pre-loaded before the below session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_Imagenet/VGG16-EPOCHS_50val_acc_0.308.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISozWwQdOPO1"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXoecsKTu8B0"
   },
   "outputs": [],
   "source": [
    "# Unfreezing \n",
    "conv_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oP3uWC3dvDcx"
   },
   "outputs": [],
   "source": [
    "# Choosing the last convolutional block for fine tuning\n",
    "set_trainable = False\n",
    "for layer in model.layers:\n",
    "  if layer.name == \"block5_conv3\":\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yE4AOHgSvbsP"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64PvwKbnvc6Q"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=28709//50,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=3589//50,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLf9IFJhvnNp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy after fine tuning')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and Validation Loss after fine tuning')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFA1NHpUvtoH"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-FZKNPdvyGk"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'val_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ym_ERHG_v61C"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_path = \"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_Imagenet/VGG16_finetune\" + epoch_str + val_acc + '.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osMkwm-C2D0e"
   },
   "source": [
    "### Fine tuning the last two Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image generators and data preparation codes are pre-loaded before the below session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_Imagenet/VGG16-EPOCHS_50val_acc_0.315.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_Y0c_E_2D0e"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIPIcI8N2D0e"
   },
   "outputs": [],
   "source": [
    "# Unfreezing \n",
    "conv_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bP6Z7S2-2D0e"
   },
   "outputs": [],
   "source": [
    "# Choosing the last two convolutional layers for fine tuning\n",
    "set_trainable = False\n",
    "for layer in model.layers:\n",
    "  if layer.name == \"block5_conv2\":\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqG5uB4F2D0f"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xpmzn6yo2D0f"
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "EPOCHS = 50\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=28709//50,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=3589//50,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KX8CSgk42D0f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy after second fine tuning')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and Validation Loss after second fine tuning')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42Yi__EP2D0f"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "go3M5iGC2D0f"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'val_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74TaVcgl2D0f"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_path = \"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_Imagenet/VGG16_finetune\" + epoch_str + val_acc + '.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6ovSSxH2PjS"
   },
   "source": [
    "### Fine tuning the last three Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image generators and data preparation codes are pre-loaded before the below session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_Imagenet/VGG16-EPOCHS_50val_acc_0.325.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXoC5XGG2PjS"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_L7oAUDe2PjS"
   },
   "outputs": [],
   "source": [
    "# Unfreezing \n",
    "conv_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-qDMuqi2PjS"
   },
   "outputs": [],
   "source": [
    "# Choosing the last three convolutional layers for fine tuning\n",
    "set_trainable = False\n",
    "for layer in model.layers:\n",
    "  if layer.name == \"block5_conv1\":\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gr7_rHy72PjS"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zov44C612PjS"
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "EPOCHS = 50\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=28709//50,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=3589//50,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DO_AwMqX2PjT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy after third fine tuning')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and Validation Loss after third fine tuning')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uL2K2Nz02PjT"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tmEwQvH2PjT"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'val_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiaK3iw22PjT"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_path = \"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/VGG16_Imagenet/VGG16_finetune\" + epoch_str + val_acc + '.h5'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nEvaluate on test data')\n",
    "results_test = model.evaluate_generator(test_generator, 3589//50)\n",
    "print('test loss, test acc:', results_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1_Transfer_learning_with_VGG16_on_fer2013.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
