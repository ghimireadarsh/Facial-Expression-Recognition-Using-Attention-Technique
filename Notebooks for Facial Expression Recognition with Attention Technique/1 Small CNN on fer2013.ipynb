{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9HZ2zZP2ABG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPool2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83225eIsAXf_"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BM4OUrNJGaE3"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTswhELQBwSn"
   },
   "outputs": [],
   "source": [
    "# Data are in dataset folder in zipped format\n",
    "!ls \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlcZtbPnB-_M"
   },
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C3Fwdx4BnHD"
   },
   "outputs": [],
   "source": [
    "# This creates a temporary folder in drive root folder, so it will have to be reloaded again when required after terminating the session\n",
    "# Permanent data are stored in dataset in zipped format\n",
    "# This copies the zipped file and store in root of google drive temporarily \n",
    "# This allows colab to run faster by taking data from root folder, rather than from actual drive location.\n",
    "! rm -rf Training; mkdir Training\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/Training.zip\" -d Training\n",
    "\n",
    "! rm -rf Validation; mkdir Validation\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/PublicTest.zip\" -d Validation\n",
    "\n",
    "! rm -rf Test; mkdir Test\n",
    "! unzip -q \"drive/My Drive/ENGR635-Deep Learning System Design Project/Dataset/fer2013/PrivateTest.zip\" -d Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0rEd4qTFZOW"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVqOHBZ2Ek2p"
   },
   "outputs": [],
   "source": [
    "!ls -l Training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9J_Y3AuiEvLH"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Training/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuFgVnVqFIr-"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Validation/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yunR8QsDFfS7"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root='Test/'\n",
    "IFS=$(echo -en \"\\n\\b\")\n",
    "(for dir in $(ls -1 \"$root\")\n",
    "    do printf \"$dir: \" && ls -i \"$root$dir\" | wc -l\n",
    " done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUjWv1Ty2ABV"
   },
   "outputs": [],
   "source": [
    "# Setting up path for training, validation and test directory\n",
    "train_dir = \"Training/\"\n",
    "validation_dir = \"Validation/\"\n",
    "test_dir = \"Test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kc4QatxPGVgf"
   },
   "source": [
    "## All data are ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up image generator with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8ELBGJViYM-"
   },
   "outputs": [],
   "source": [
    "# Image height and width initialization\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator setup\n",
    "batch_size = 50\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   featurewise_center=False,\n",
    "                                   featurewise_std_normalization=False,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True\n",
    "                                   )\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(validation_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight_computer():\n",
    "  \"\"\"\n",
    "  This function generates the class weights based on training data.\n",
    "  \n",
    "    Training Data categories and number of samples in them\n",
    "    Angry: 3995\n",
    "    Disgust: 436\n",
    "    Fear: 4097\n",
    "    Happy: 7215\n",
    "    Neutral: 4965\n",
    "    Sad: 4830\n",
    "    Surprise: 3171\n",
    "  \"\"\"\n",
    "  samples_per_label = [3995, 436, 4097, 7215, 4965, 4830, 3171]\n",
    "  total_samples = sum(samples_per_label)\n",
    "  return dict([(i, total_samples/(7*j)) for (i,j) in enumerate(samples_per_label)]) \n",
    "\n",
    "class_weights = class_weight_computer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Small CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCBKZp9vG2zW"
   },
   "outputs": [],
   "source": [
    "DROP_OUT = 0.5\n",
    "# Building network based on CNN layer only\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), strides=2, input_shape=(img_height, img_width, 3), activation=\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(DROP_OUT))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), strides=2, activation=\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(DROP_OUT))\n",
    "\n",
    "# Third convolutional layer\n",
    "model.add(Conv2D(128, (3, 3), strides=2, activation=\"relu\"))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(DROP_OUT))\n",
    "\n",
    "# Flattening the convolution layers output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001,), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyDmy4jw2AB3"
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "EPOCHS = 50\n",
    "training_samples = 28709\n",
    "validation_samples = 3589\n",
    "test_samples = 3589\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=training_samples//batch_size,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_samples//batch_size,\n",
    "    shuffle=True,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEpAZsie2AB9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', label=\"Validation accuracy\")\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97OLeZqGMUvH"
   },
   "outputs": [],
   "source": [
    "print('\\nEvaluate on Validation data')\n",
    "results_validation = model.evaluate_generator(validation_generator, validation_samples//batch_size)\n",
    "print('Validation loss, Validation Accuracy:', results_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmPrecLaMwpV"
   },
   "outputs": [],
   "source": [
    "epoch_str = '-EPOCHS_' + str(EPOCHS)\n",
    "val_acc = 'val_acc_%.3f' % results_validation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR2kw25cN8gZ"
   },
   "outputs": [],
   "source": [
    "print(epoch_str)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfWTZzbvNiG5"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"drive/My Drive/ENGR635-Deep Learning System Design Project/Models/Benchmark/\" + 'Benchmark' + epoch_str + val_acc + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nEvaluate on test data')\n",
    "results_test = model.evaluate_generator(test_generator, test_samples//batch_size)\n",
    "print('test loss, test acc:', results_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1_Benchmark_on_fer2013.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
